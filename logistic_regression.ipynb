{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Inventory Sampled Shape: (91182, 51)\n",
      "Roads Sampled Shape: (19791, 52)\n",
      "Census Income Sampled Shape: (380, 281)\n",
      "Air Quality Sampled Shape: (368, 32)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6929832 entries, 0 to 6929831\n",
      "Columns: 416 entries, OBJECTID_left to Shape__Length\n",
      "dtypes: float64(334), int64(9), object(73)\n",
      "memory usage: 21.5+ GB\n",
      "None\n",
      "   OBJECTID_left    TREEID  Closest Civic Number      STREET LOCATION_left  \\\n",
      "0              1  10007057                  27.0  ACTIVA AVE     BOULEVARD   \n",
      "1              1  10007057                  27.0  ACTIVA AVE     BOULEVARD   \n",
      "2              1  10007057                  27.0  ACTIVA AVE     BOULEVARD   \n",
      "3              1  10007057                  27.0  ACTIVA AVE     BOULEVARD   \n",
      "4              1  10007057                  27.0  ACTIVA AVE     BOULEVARD   \n",
      "\n",
      "                     SPECIES_NAME  \\\n",
      "0  Autumn Brilliance Serviceberry   \n",
      "1  Autumn Brilliance Serviceberry   \n",
      "2  Autumn Brilliance Serviceberry   \n",
      "3  Autumn Brilliance Serviceberry   \n",
      "4  Autumn Brilliance Serviceberry   \n",
      "\n",
      "                                   SPECIES_LATIN SPECIES_CODE LANDUSE  \\\n",
      "0  Amelanchier x grandiflora 'Autumn Brilliance'       AMGRAB     ROW   \n",
      "1  Amelanchier x grandiflora 'Autumn Brilliance'       AMGRAB     ROW   \n",
      "2  Amelanchier x grandiflora 'Autumn Brilliance'       AMGRAB     ROW   \n",
      "3  Amelanchier x grandiflora 'Autumn Brilliance'       AMGRAB     ROW   \n",
      "4  Amelanchier x grandiflora 'Autumn Brilliance'       AMGRAB     ROW   \n",
      "\n",
      "   ROADSEGMENTID  ... TOT_INC_ADJ_EIGHTH_DECILE  TOT_INC_ADJ_NINTH_DECILE  \\\n",
      "0          40056  ...                       NaN                       NaN   \n",
      "1          40056  ...                       NaN                       NaN   \n",
      "2          40056  ...                       NaN                       NaN   \n",
      "3          40056  ...                       NaN                       NaN   \n",
      "4          40056  ...                       NaN                       NaN   \n",
      "\n",
      "  TOT_INC_ADJ_TOP_DECILE TOT_INEQUALITY_MEASURE  \\\n",
      "0                    NaN                    NaN   \n",
      "1                    NaN                    NaN   \n",
      "2                    NaN                    NaN   \n",
      "3                    NaN                    NaN   \n",
      "4                    NaN                    NaN   \n",
      "\n",
      "   GINI_INDEX_ADJUST_HHLD_TOT_INC GINI_INDEX_ADJUST_HHLD_MRK_INC  \\\n",
      "0                             NaN                            NaN   \n",
      "1                             NaN                            NaN   \n",
      "2                             NaN                            NaN   \n",
      "3                             NaN                            NaN   \n",
      "4                             NaN                            NaN   \n",
      "\n",
      "  GINI_INDEX_ADJUST_HHLD_AT_INC P90P10RATIO_ADJUST_HHLD_AT_INC Shape__Area  \\\n",
      "0                           NaN                            NaN         NaN   \n",
      "1                           NaN                            NaN         NaN   \n",
      "2                           NaN                            NaN         NaN   \n",
      "3                           NaN                            NaN         NaN   \n",
      "4                           NaN                            NaN         NaN   \n",
      "\n",
      "  Shape__Length  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4           NaN  \n",
      "\n",
      "[5 rows x 416 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m     87\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Predict and evaluate the model\u001b[39;00m\n\u001b[1;32m     91\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import gc\n",
    "\n",
    "# Define a function to load data in chunks\n",
    "def load_data_in_chunks(file_path, chunksize=10000):\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize, encoding='unicode_escape'):\n",
    "        chunks.append(chunk)\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Load datasets in chunks\n",
    "tree_inventory = load_data_in_chunks('tree_inventory.csv')\n",
    "roads = load_data_in_chunks('roads.csv')\n",
    "census_income = load_data_in_chunks('census_2021_income.csv')\n",
    "air_quality = load_data_in_chunks('reduced_air_quality.csv')\n",
    "\n",
    "\n",
    "# Display the shape of sampled datasets\n",
    "print(f'Tree Inventory Sampled Shape: {tree_inventory.shape}')\n",
    "print(f'Roads Sampled Shape: {roads.shape}')\n",
    "print(f'Census Income Sampled Shape: {census_income.shape}')\n",
    "print(f'Air Quality Sampled Shape: {air_quality.shape}')\n",
    "\n",
    "\n",
    "\n",
    "# Function to create GeoDataFrame\n",
    "def create_geodataframe(df, lon_col, lat_col):\n",
    "    df['geometry'] = df.apply(lambda row: Point(row[lon_col], row[lat_col]), axis=1)\n",
    "    return gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Create GeoDataFrames\n",
    "gdf_tree_inventory = create_geodataframe(tree_inventory, 'x', 'y')\n",
    "gdf_air_quality = create_geodataframe(air_quality, 'POD_LONGITUDE', 'POD_LATITUDE')\n",
    "\n",
    "\n",
    "\n",
    "# Function to perform spatial join in chunks\n",
    "def spatial_join_in_chunks(left_gdf, right_gdf, batch_size=1000):\n",
    "    result_list = []\n",
    "    for i in range(0, len(left_gdf), batch_size):\n",
    "        batch = left_gdf.iloc[i:i+batch_size]\n",
    "        merged_batch = gpd.sjoin_nearest(batch, right_gdf, how='left')\n",
    "        result_list.append(merged_batch)\n",
    "        # Free up memory\n",
    "        del batch, merged_batch\n",
    "        gc.collect()\n",
    "    return pd.concat(result_list, ignore_index=True)\n",
    "\n",
    "# Perform spatial join in chunks\n",
    "tree_air_quality_merged = spatial_join_in_chunks(gdf_tree_inventory, gdf_air_quality)\n",
    "\n",
    "# Drop geometry columns\n",
    "tree_air_quality_merged = tree_air_quality_merged.drop(columns=['geometry', 'index_right'])\n",
    "\n",
    "# Merge with roads based on 'OBJECTID_left'\n",
    "tree_air_roads_merged = tree_air_quality_merged.merge(roads, left_on='OBJECTID_left', right_on='OBJECTID', how='left')\n",
    "\n",
    "# Merge with census_income based on a relevant geographical or demographical identifier\n",
    "# Ensure both DataFrames have a common column for merging\n",
    "final_merged_df = tree_air_roads_merged.merge(census_income, left_on='GeoID', right_on='GEO_CODE', how='left')\n",
    "\n",
    "# Display the final merged DataFrame info\n",
    "print(final_merged_df.info())\n",
    "print(final_merged_df.head())\n",
    "\n",
    "# Assuming 'IN_NEED_REGION' is a binary target variable (0 - not in need, 1 - in need)\n",
    "final_merged_df['IN_NEED_REGION'] = (final_merged_df['POP_2021'] < final_merged_df['POP_2021'].median()).astype(int)  # Example criteria\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['POP_2021', 'TOT_INC_STAT_2020_15PLUS']\n",
    "target = 'IN_NEED_REGION'\n",
    "\n",
    "# Handle missing values\n",
    "X = final_merged_df[features].fillna(0)\n",
    "y = final_merged_df[target].fillna(0)\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Initialize and train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Assuming 'IN_NEED_REGION' is a binary target variable (0 - not in need, 1 - in need)\n",
    "final_merged_df['IN_NEED_REGION'] = (final_merged_df['POP_2021'] < final_merged_df['POP_2021'].median()).astype(int)  # Example criteria\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['POP_2021', 'TOT_INC_STAT_2020_15PLUS']\n",
    "target = 'IN_NEED_REGION'\n",
    "\n",
    "# Handle missing values\n",
    "X = final_merged_df[features].fillna(0)\n",
    "y = final_merged_df[target].fillna(0)\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Initialize and train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
